{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48a10272-a373-43d6-af58-a66c544a503a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded\n",
      "Image loaded\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your specific input files\n",
    "img1 = cv2.imread(\"image_panaroma/input1.png\")\n",
    "img2 = cv2.imread(\"image_panaroma/input2.png\")\n",
    "\n",
    "# Store in a list\n",
    "imgs = [img1, img2]\n",
    "\n",
    "# Check if images loaded\n",
    "for i, img in enumerate(imgs):\n",
    "    if img is None:\n",
    "        print(f\"Image failed to load\")\n",
    "    else:\n",
    "        print(f\"Image loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "439c4ca2-ee5f-4cb1-8594-cafe9b71df50",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()\n",
    "keypoints = []\n",
    "descriptors = []\n",
    "\n",
    "for img in imgs:\n",
    "    kp, des = sift.detectAndCompute(img, None)\n",
    "    keypoints.append(kp)\n",
    "    descriptors.append(des)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cea357c-a702-4260-a8c7-206af66a25f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "num_imgs = len(descriptors)\n",
    "adjacency_matrix = np.zeros((num_imgs, num_imgs), dtype=int)\n",
    "np.fill_diagonal(adjacency_matrix, 1)\n",
    "\n",
    "for idx1 in range(num_imgs):\n",
    "    for idx2 in range(idx1 + 1, num_imgs):\n",
    "        desc_a = descriptors[idx1]\n",
    "        desc_b = descriptors[idx2]\n",
    "\n",
    "        if desc_a is None or desc_b is None:\n",
    "            continue\n",
    "            \n",
    "        avg_sim = np.mean(cosine_similarity(desc_a, desc_b))\n",
    "        \n",
    "        matches_a_to_b = []\n",
    "        matches_b_to_a = []\n",
    "        \n",
    "        for i, vec_a in enumerate(desc_a):\n",
    "            distances = np.linalg.norm(desc_b - vec_a, axis=1)\n",
    "            best_match = np.argmin(distances)\n",
    "            matches_a_to_b.append((i, best_match))\n",
    "            \n",
    "        for j, vec_b in enumerate(desc_b):\n",
    "            distances = np.linalg.norm(desc_a - vec_b, axis=1)\n",
    "            best_match = np.argmin(distances)\n",
    "            matches_b_to_a.append((best_match, j))\n",
    "            \n",
    "        mutual_matches = set(matches_a_to_b) & set(matches_b_to_a)\n",
    "        \n",
    "        good_matches = []\n",
    "        for i, vec_a in enumerate(desc_a):\n",
    "            distances = np.linalg.norm(desc_b - vec_a, axis=1)\n",
    "            sorted_indices = np.argsort(distances)\n",
    "            if distances[sorted_indices[0]] < 0.7 * distances[sorted_indices[1]]:\n",
    "                good_matches.append((i, sorted_indices[0]))\n",
    "                \n",
    "        min_keypoints = min(len(desc_a), len(desc_b))\n",
    "        threshold = max(4, 0.15 * min_keypoints)\n",
    "        \n",
    "        if (len(mutual_matches) > threshold) or (avg_sim > 0.5 and len(good_matches) > threshold//2):\n",
    "            adjacency_matrix[idx1][idx2] = 1\n",
    "            adjacency_matrix[idx2][idx1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5dc30a7-fc47-4a37-b87b-2cc4e23a8977",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_counts = np.sum(adjacency_matrix, axis=1)\n",
    "reference_idx = np.argmax(connection_counts)\n",
    "\n",
    "num_images = len(descriptors)\n",
    "homographies = [np.eye(3) if i == reference_idx else None for i in range(num_images)]\n",
    "\n",
    "match_ratio_threshold = 0.7\n",
    "min_match_ratio = 0.15\n",
    "ransac_thresh = 3.0\n",
    "\n",
    "for current_idx in range(num_images):\n",
    "    if current_idx == reference_idx:\n",
    "        continue\n",
    "    if descriptors[current_idx] is None or descriptors[reference_idx] is None:\n",
    "        continue\n",
    "    \n",
    "    current_desc = descriptors[current_idx]\n",
    "    reference_desc = descriptors[reference_idx]\n",
    "    good_matches = []\n",
    "    \n",
    "    for feat_idx, feat_vec in enumerate(current_desc):\n",
    "        distances = np.linalg.norm(reference_desc - feat_vec, axis=1)\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        best_dist = distances[sorted_indices[0]]\n",
    "        second_dist = distances[sorted_indices[1]]\n",
    "        \n",
    "        if best_dist < match_ratio_threshold * second_dist:\n",
    "            good_matches.append((feat_idx, sorted_indices[0]))\n",
    "    \n",
    "    min_kpts = min(len(keypoints[current_idx]), len(keypoints[reference_idx]))\n",
    "    required_matches = max(4, int(min_kpts * min_match_ratio))\n",
    "    \n",
    "    if len(good_matches) >= required_matches:\n",
    "        src_points = np.float32([keypoints[current_idx][m[0]].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_points = np.float32([keypoints[reference_idx][m[1]].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        \n",
    "        H, _ = cv2.findHomography(src_points, dst_points, cv2.RANSAC, ransac_thresh)\n",
    "        \n",
    "        if H is not None:\n",
    "            homographies[current_idx] = H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dec4764f-3b9a-4351-9dd3-280a5b7a910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_ref, w_ref = imgs[reference_idx].shape[:2]\n",
    "corners = np.float32([[0, 0], [0, h_ref], [w_ref, h_ref], [w_ref, 0]]).reshape(-1, 1, 2)\n",
    "\n",
    "all_corners = []\n",
    "for i in range(num_imgs):\n",
    "    if homographies[i] is None:\n",
    "        continue\n",
    "    h_i, w_i = imgs[i].shape[:2]\n",
    "    img_corners = np.float32([[0, 0], [0, h_i], [w_i, h_i], [w_i, 0]]).reshape(-1, 1, 2)\n",
    "    warped_corners = cv2.perspectiveTransform(img_corners, homographies[i])\n",
    "    all_corners.append(warped_corners)\n",
    "\n",
    "all_pts = np.concatenate(all_corners, axis=0)\n",
    "[xmin, ymin] = np.int32(all_pts.min(axis=0).ravel() - 0.5)\n",
    "[xmax, ymax] = np.int32(all_pts.max(axis=0).ravel() + 0.5)\n",
    "\n",
    "width = xmax - xmin\n",
    "height = ymax - ymin\n",
    "translation = np.array([[1, 0, -xmin], [0, 1, -ymin], [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55a797b5-53c1-4791-8a73-98c917411462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panorama = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "\n",
    "for i in range(num_imgs):\n",
    "    if homographies[i] is None:\n",
    "        continue\n",
    "    H_translated = translation @ homographies[i]\n",
    "    warped_img = cv2.warpPerspective(imgs[i], H_translated, (width, height))\n",
    "    mask = (panorama == 0)\n",
    "    panorama[mask] = warped_img[mask]\n",
    "\n",
    "cv2.imshow(\"Panorama\", panorama)\n",
    "cv2.imwrite(\"output.png\", panorama)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
